{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BallDetector:\n",
    "    \n",
    "    def __init__(self, bin_threshold):\n",
    "        self.bin_threshold\n",
    "#         self.hue_min = hue_min\n",
    "#         self.hue_max = hue_max\n",
    "#         self.saturation = saturation\n",
    "#         self.value = value\n",
    "#         self.kernel_size = kernel_size\n",
    "#         self.min_area = min_area\n",
    "#         self.flimits = flimits\n",
    "\n",
    "    def detect(self, img):\n",
    "        img_bin=self.binarization(img)\n",
    "        \n",
    "#         seg = self.segmentation(img)\n",
    "#         seg = self.post_processing(seg)\n",
    "        \n",
    "#         curve = self.polygonal_curve_detection(seg)\n",
    "        return img_bin\n",
    "#         return seg, curve\n",
    "    def binarization(self,img):\n",
    "        ret,th1 = cv.threshold(img,127,255,cv.THRESH_BINARY)\n",
    "        th2 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_MEAN_C,cv.THRESH_BINARY,11,2)\n",
    "        th3 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C,cv.THRESH_BINARY,11,2)\n",
    "        titles = ['Original Image', 'Global Thresholding (v = 127)','Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']\n",
    "        images = [img, th1, th2, th3]\n",
    "        for i in xrange(4):\n",
    "            plt.subplot(2,2,i+1),plt.imshow(images[i],'gray')\n",
    "            plt.title(titles[i])\n",
    "            plt.xticks([]),plt.yticks([])\n",
    "        plt.show()\n",
    "\n",
    "#     def segmentation(self, img):\n",
    "#         hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        \n",
    "#         h = hsv[:, :, 0]\n",
    "#         s = hsv[:, :, 1]\n",
    "#         v = hsv[:, :, 2]\n",
    "        \n",
    "#         color_segment = (\n",
    "#             np.logical_and(\n",
    "#                 h > self.hue_min,\n",
    "#                 h <= self.hue_max)\n",
    "#             if self.hue_min < self.hue_max\n",
    "#             else \n",
    "#             np.logical_or(\n",
    "#                 h > self.hue_min,\n",
    "#                 h < self.hue_max))\n",
    "        \n",
    "#         binary = np.logical_and.reduce([\n",
    "#             color_segment,\n",
    "#             s > self.saturation,\n",
    "#             v > self.value\n",
    "#             ])\n",
    "#         binary = binary * 255\n",
    "        \n",
    "#         return binary.astype('u1')\n",
    "        \n",
    "    \n",
    "#     def post_processing(self, img):\n",
    "#         kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (self.kernel_size, self.kernel_size))\n",
    "#         binary = cv2.erode(img, kernel)\n",
    "#         binary = cv2.dilate(binary, kernel)\n",
    "#         # binary = cv2.GaussianBlur(binary, (5,5), 2,2)\n",
    "#         return binary\n",
    "\n",
    "#     def polygonal_curve_detection(self, binary):\n",
    "#         contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        \n",
    "#         contours = [ cv2.convexHull(c) for c in contours ]\n",
    "\n",
    "#         if len(contours) == 0:\n",
    "#             return None\n",
    "\n",
    "#         contourAreas = [ cv2.contourArea(c) for c in contours ]\n",
    "#         contourId = np.argmax(contourAreas)\n",
    "#         contour = contours[contourId]\n",
    "\n",
    "#         area = cv2.contourArea(contour)\n",
    "#         bbox = cv2.boundingRect(contour)\n",
    "#         bbox = tuple(map(float, bbox))\n",
    "#         radius = bbox[2] / 2\n",
    "\n",
    "#         if area < self.min_area:\n",
    "#             return None\n",
    "\n",
    "#         ffac1 = np.abs(1 - (bbox[2] / bbox[3]))\n",
    "#         ffac2 = np.abs(1 - area / (np.pi * radius * radius))\n",
    "        \n",
    "#         is_circle = ffac1 < self.flimits[0] and ffac2 < self.flimits[1]\n",
    "#         if not is_circle:\n",
    "#             return None\n",
    "\n",
    "#         centroid = ( (bbox[0] + radius, bbox[1]+ radius), radius )\n",
    "\n",
    "#         return centroid\n",
    "\n",
    "#     def hough_lines(self):\n",
    "#         return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Adjusting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets.widgets import interact, interact_manual\n",
    "from ipywidgets.widgets import (IntSlider, FloatSlider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = glob('top_left_camera/*.png')[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [cv2.imread(img) for img in imgs]\n",
    "imgs = [cv2.cvtColor(img, cv2.COLOR_BGR2RGB) for img in imgs ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3adb8a15a7d74be1aa2ec7f48ab2a039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=170, description='hue_min', max=180), IntSlider(value=20, description='hâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual(\n",
    "    hue_max=IntSlider(min=0, max=180, value=20),\n",
    "    hue_min=IntSlider(min=0, max=180, value=170),\n",
    "    saturation=IntSlider(min=0, max=255, value=150),\n",
    "    value=IntSlider(min=0, max=255, value=30),\n",
    "    min_area=FloatSlider(min=1000, max=20000, value=10000),\n",
    "    kernel_size=IntSlider(min=3, max=15, value=5),\n",
    "    flim1=FloatSlider(min=0, max=1, value=0.10),\n",
    "    flim2=FloatSlider(min=0, max=1, value=0.15),)\n",
    "def f(hue_min, hue_max, saturation, value, min_area, kernel_size, flim1, flim2):\n",
    "    fig, axarr = plt.subplots(5,6, figsize=(15,12))\n",
    "    ax = axarr.flatten()\n",
    "    \n",
    "    bd = BallDetector(hue_max=hue_max,\n",
    "                      hue_min=hue_min,\n",
    "                      saturation=saturation,\n",
    "                      value=value,\n",
    "                      kernel_size=kernel_size,\n",
    "                      min_area=min_area,\n",
    "                      flimits=(flim1, flim2))\n",
    "    \n",
    "    segmentations, detections = zip(*[ bd.detect(img) for img in imgs ])\n",
    "    \n",
    "    for i in range(30):\n",
    "        ax[i].axis('off')\n",
    "        ax[i].imshow(imgs[i], alpha=1)\n",
    "        ax[i].imshow(segmentations[i], cmap='gray', alpha=0.5)\n",
    "        ax[i].legend(str(i))\n",
    "\n",
    "        if detections[i] is not None:\n",
    "            t = np.linspace(0, 2 * np.pi, 200)\n",
    "\n",
    "            (x, y), r = detections[i]\n",
    "            x += r * np.cos(t)\n",
    "            y += r * np.sin(t)\n",
    "            ax[i].plot(x, y, c='r')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect the ball in all frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from os.path import split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = glob('/home/daniela/Documents/SeaAI/thermal_camera/*.png')\n",
    "imgs = sorted(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the ball detector with the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd = BallDetector(hue_max=20,\n",
    "                  hue_min=170,\n",
    "                  saturation=150,\n",
    "                  value=30,\n",
    "                  kernel_size=5,\n",
    "                  min_area=8000,\n",
    "                  flimits=(0.10, 0.15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d5540783224ea88e7ba877c5f04f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=505), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-67bfdcbc288c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mrgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdetection\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-03c5eaded59d>\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mcurve\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolygonal_curve_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-03c5eaded59d>\u001b[0m in \u001b[0;36mpolygonal_curve_detection\u001b[0;34m(self, binary)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpolygonal_curve_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mcontours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindContours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETR_EXTERNAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHAIN_APPROX_NONE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mcontours\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvexHull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontours\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "detections = []\n",
    "timestamps = []\n",
    "for img in tqdm_notebook(imgs):\n",
    "    _, name = split(img)\n",
    "    timestamp = name[:-4]\n",
    "    \n",
    "    im = cv2.imread(str(img))\n",
    "    rgb = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    _, detection = bd.detect(rgb)\n",
    "    \n",
    "    if detection is not None:\n",
    "        detections.append(detection)\n",
    "        timestamps.append(timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create annotated video from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_writer = cv2.VideoWriter('./video.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 30.0, (964, 724))\n",
    "\n",
    "for img in tqdm_notebook(imgs):\n",
    "    im = cv2.imread(str(img))\n",
    "    rgb = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    _, detection = bd.detect(rgb)\n",
    "\n",
    "    if detection is not None:\n",
    "        (x, y), r = detection\n",
    "        \n",
    "        im = cv2.circle(im, (int(x), int(y)), int(r), (0, 255, 0), 4)\n",
    "    \n",
    "    video_writer.write(im)\n",
    "\n",
    "video_writer.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform 2D detection into 3D points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Intrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx = 1167.914995\n",
    "fy = 1178.789838\n",
    "favg = (fx + fy) / 2\n",
    "cx = 505.998418\n",
    "cy = 375.348091\n",
    "K = np.array([fx, 0, cx, 0, fy, cy, 0, 0, 1]).reshape(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ball_diameter = 2.24 / (np.pi)\n",
    "ball_diameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uvz2xyz(detection):\n",
    "    (x, y), r = detection\n",
    "    \n",
    "    dist = favg * ball_diameter / r / 2\n",
    "    p = np.array([x, y, 1]).astype('f4')\n",
    "    \n",
    "    return dist * la.inv(K).dot(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = map(uvz2xyz, detections)\n",
    "points = list(points)\n",
    "points = np.array(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Smooth the points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = np.array_split(points, points.shape[0] // 10)\n",
    "points_smooth = map(lambda c: np.mean(c, axis=0), chunks)\n",
    "points_smooth = np.stack(points_smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Path of the ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(points_smooth[:, 0], points_smooth[:, 1])\n",
    "plt.scatter(points[:, 0], points[:, 1], s=5, c='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
